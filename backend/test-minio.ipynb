{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket 'auctus' already exists\n",
      "df (2).parquet\n"
     ]
    }
   ],
   "source": [
    "from minio import Minio\n",
    "\n",
    "client = Minio(\n",
    "        \"play.min.io\",\n",
    "        access_key=\"minioadmin\",\n",
    "        secret_key=\"minioadmin\",\n",
    "    )\n",
    "\n",
    "    # Make 'asiatrip' bucket if not exist.\n",
    "found = client.bucket_exists(\"auctus\")\n",
    "if not found:\n",
    "        client.make_bucket(\"auctus\")\n",
    "else:\n",
    "        print(\"Bucket 'auctus' already exists\")\n",
    "objects = client.list_objects(\"auctus\", recursive=True)\n",
    "for obj in objects:\n",
    "    print(obj.object_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auctus-ssm\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "s3 = boto3.resource(\n",
    "    service_name='s3',\n",
    "    region_name='us-east-2',\n",
    "    aws_access_key_id='AKIAVBQNNS3MXTP637OG',\n",
    "    aws_secret_access_key='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'\n",
    ")\n",
    "for bucket in s3.buckets.all():\n",
    "    print(bucket.name)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 1 records to file.parquet\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Install s3fs to access S3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/software/anaconda3/envs/spark/lib/python3.9/site-packages/aiohttp/client_reqrep.py:70\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mcchardet\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mchardet\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:  \u001b[39m# pragma: no cover\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cchardet'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/software/anaconda3/envs/spark/lib/python3.9/site-packages/fsspec/registry.py:216\u001b[0m, in \u001b[0;36mget_filesystem_class\u001b[0;34m(protocol)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 216\u001b[0m     register_implementation(protocol, _import_class(bit[\u001b[39m\"\u001b[39;49m\u001b[39mclass\u001b[39;49m\u001b[39m\"\u001b[39;49m]))\n\u001b[1;32m    217\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/software/anaconda3/envs/spark/lib/python3.9/site-packages/fsspec/registry.py:239\u001b[0m, in \u001b[0;36m_import_class\u001b[0;34m(cls, minv)\u001b[0m\n\u001b[1;32m    238\u001b[0m mod, name \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mrsplit(\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[0;32m--> 239\u001b[0m mod \u001b[39m=\u001b[39m importlib\u001b[39m.\u001b[39;49mimport_module(mod)\n\u001b[1;32m    240\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39m(mod, name)\n",
      "File \u001b[0;32m~/software/anaconda3/envs/spark/lib/python3.9/importlib/__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    126\u001b[0m         level \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 127\u001b[0m \u001b[39mreturn\u001b[39;00m _bootstrap\u001b[39m.\u001b[39;49m_gcd_import(name[level:], package, level)\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1030\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1007\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:986\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:680\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:850\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:228\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m~/software/anaconda3/envs/spark/lib/python3.9/site-packages/s3fs/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m S3FileSystem, S3File\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmapping\u001b[39;00m \u001b[39mimport\u001b[39;00m S3Map\n",
      "File \u001b[0;32m~/software/anaconda3/envs/spark/lib/python3.9/site-packages/s3fs/core.py:29\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mbotocore\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39maiobotocore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msession\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39maiobotocore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconfig\u001b[39;00m \u001b[39mimport\u001b[39;00m AioConfig\n",
      "File \u001b[0;32m~/software/anaconda3/envs/spark/lib/python3.9/site-packages/aiobotocore/session.py:12\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m retryhandler\n\u001b[0;32m---> 12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mclient\u001b[39;00m \u001b[39mimport\u001b[39;00m AioBaseClient, AioClientCreator\n\u001b[1;32m     13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mconfigprovider\u001b[39;00m \u001b[39mimport\u001b[39;00m AioSmartDefaultsConfigStoreFactory\n",
      "File \u001b[0;32m~/software/anaconda3/envs/spark/lib/python3.9/site-packages/aiobotocore/client.py:18\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m waiter\n\u001b[0;32m---> 18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39margs\u001b[39;00m \u001b[39mimport\u001b[39;00m AioClientArgsCreator\n\u001b[1;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdiscovery\u001b[39;00m \u001b[39mimport\u001b[39;00m AioEndpointDiscoveryHandler, AioEndpointDiscoveryManager\n",
      "File \u001b[0;32m~/software/anaconda3/envs/spark/lib/python3.9/site-packages/aiobotocore/args.py:8\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mconfig\u001b[39;00m \u001b[39mimport\u001b[39;00m AioConfig\n\u001b[0;32m----> 8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mendpoint\u001b[39;00m \u001b[39mimport\u001b[39;00m AioEndpointCreator\n\u001b[1;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mregions\u001b[39;00m \u001b[39mimport\u001b[39;00m AioEndpointRulesetResolver\n",
      "File \u001b[0;32m~/software/anaconda3/envs/spark/lib/python3.9/site-packages/aiobotocore/endpoint.py:19\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39maiobotocore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mhttpchecksum\u001b[39;00m \u001b[39mimport\u001b[39;00m handle_checksum_body\n\u001b[0;32m---> 19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39maiobotocore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mhttpsession\u001b[39;00m \u001b[39mimport\u001b[39;00m AIOHTTPSession\n\u001b[1;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39maiobotocore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mresponse\u001b[39;00m \u001b[39mimport\u001b[39;00m StreamingBody\n",
      "File \u001b[0;32m~/software/anaconda3/envs/spark/lib/python3.9/site-packages/aiobotocore/httpsession.py:7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m Dict, Optional\n\u001b[0;32m----> 7\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39maiohttp\u001b[39;00m  \u001b[39m# lgtm [py/import-and-import-from]\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39maiohttp\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m      9\u001b[0m     ClientConnectionError,\n\u001b[1;32m     10\u001b[0m     ClientConnectorError,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m     ServerTimeoutError,\n\u001b[1;32m     16\u001b[0m )\n",
      "File \u001b[0;32m~/software/anaconda3/envs/spark/lib/python3.9/site-packages/aiohttp/__init__.py:6\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m hdrs \u001b[39mas\u001b[39;00m hdrs\n\u001b[0;32m----> 6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mclient\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m      7\u001b[0m     BaseConnector \u001b[39mas\u001b[39;00m BaseConnector,\n\u001b[1;32m      8\u001b[0m     ClientConnectionError \u001b[39mas\u001b[39;00m ClientConnectionError,\n\u001b[1;32m      9\u001b[0m     ClientConnectorCertificateError \u001b[39mas\u001b[39;00m ClientConnectorCertificateError,\n\u001b[1;32m     10\u001b[0m     ClientConnectorError \u001b[39mas\u001b[39;00m ClientConnectorError,\n\u001b[1;32m     11\u001b[0m     ClientConnectorSSLError \u001b[39mas\u001b[39;00m ClientConnectorSSLError,\n\u001b[1;32m     12\u001b[0m     ClientError \u001b[39mas\u001b[39;00m ClientError,\n\u001b[1;32m     13\u001b[0m     ClientHttpProxyError \u001b[39mas\u001b[39;00m ClientHttpProxyError,\n\u001b[1;32m     14\u001b[0m     ClientOSError \u001b[39mas\u001b[39;00m ClientOSError,\n\u001b[1;32m     15\u001b[0m     ClientPayloadError \u001b[39mas\u001b[39;00m ClientPayloadError,\n\u001b[1;32m     16\u001b[0m     ClientProxyConnectionError \u001b[39mas\u001b[39;00m ClientProxyConnectionError,\n\u001b[1;32m     17\u001b[0m     ClientRequest \u001b[39mas\u001b[39;00m ClientRequest,\n\u001b[1;32m     18\u001b[0m     ClientResponse \u001b[39mas\u001b[39;00m ClientResponse,\n\u001b[1;32m     19\u001b[0m     ClientResponseError \u001b[39mas\u001b[39;00m ClientResponseError,\n\u001b[1;32m     20\u001b[0m     ClientSession \u001b[39mas\u001b[39;00m ClientSession,\n\u001b[1;32m     21\u001b[0m     ClientSSLError \u001b[39mas\u001b[39;00m ClientSSLError,\n\u001b[1;32m     22\u001b[0m     ClientTimeout \u001b[39mas\u001b[39;00m ClientTimeout,\n\u001b[1;32m     23\u001b[0m     ClientWebSocketResponse \u001b[39mas\u001b[39;00m ClientWebSocketResponse,\n\u001b[1;32m     24\u001b[0m     ContentTypeError \u001b[39mas\u001b[39;00m ContentTypeError,\n\u001b[1;32m     25\u001b[0m     Fingerprint \u001b[39mas\u001b[39;00m Fingerprint,\n\u001b[1;32m     26\u001b[0m     InvalidURL \u001b[39mas\u001b[39;00m InvalidURL,\n\u001b[1;32m     27\u001b[0m     NamedPipeConnector \u001b[39mas\u001b[39;00m NamedPipeConnector,\n\u001b[1;32m     28\u001b[0m     RequestInfo \u001b[39mas\u001b[39;00m RequestInfo,\n\u001b[1;32m     29\u001b[0m     ServerConnectionError \u001b[39mas\u001b[39;00m ServerConnectionError,\n\u001b[1;32m     30\u001b[0m     ServerDisconnectedError \u001b[39mas\u001b[39;00m ServerDisconnectedError,\n\u001b[1;32m     31\u001b[0m     ServerFingerprintMismatch \u001b[39mas\u001b[39;00m ServerFingerprintMismatch,\n\u001b[1;32m     32\u001b[0m     ServerTimeoutError \u001b[39mas\u001b[39;00m ServerTimeoutError,\n\u001b[1;32m     33\u001b[0m     TCPConnector \u001b[39mas\u001b[39;00m TCPConnector,\n\u001b[1;32m     34\u001b[0m     TooManyRedirects \u001b[39mas\u001b[39;00m TooManyRedirects,\n\u001b[1;32m     35\u001b[0m     UnixConnector \u001b[39mas\u001b[39;00m UnixConnector,\n\u001b[1;32m     36\u001b[0m     WSServerHandshakeError \u001b[39mas\u001b[39;00m WSServerHandshakeError,\n\u001b[1;32m     37\u001b[0m     request \u001b[39mas\u001b[39;00m request,\n\u001b[1;32m     38\u001b[0m )\n\u001b[1;32m     39\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcookiejar\u001b[39;00m \u001b[39mimport\u001b[39;00m CookieJar \u001b[39mas\u001b[39;00m CookieJar, DummyCookieJar \u001b[39mas\u001b[39;00m DummyCookieJar\n",
      "File \u001b[0;32m~/software/anaconda3/envs/spark/lib/python3.9/site-packages/aiohttp/client.py:59\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mclient_exceptions\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     39\u001b[0m     ClientConnectionError \u001b[39mas\u001b[39;00m ClientConnectionError,\n\u001b[1;32m     40\u001b[0m     ClientConnectorCertificateError \u001b[39mas\u001b[39;00m ClientConnectorCertificateError,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     57\u001b[0m     WSServerHandshakeError \u001b[39mas\u001b[39;00m WSServerHandshakeError,\n\u001b[1;32m     58\u001b[0m )\n\u001b[0;32m---> 59\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mclient_reqrep\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     60\u001b[0m     ClientRequest \u001b[39mas\u001b[39;00m ClientRequest,\n\u001b[1;32m     61\u001b[0m     ClientResponse \u001b[39mas\u001b[39;00m ClientResponse,\n\u001b[1;32m     62\u001b[0m     Fingerprint \u001b[39mas\u001b[39;00m Fingerprint,\n\u001b[1;32m     63\u001b[0m     RequestInfo \u001b[39mas\u001b[39;00m RequestInfo,\n\u001b[1;32m     64\u001b[0m     _merge_ssl_params,\n\u001b[1;32m     65\u001b[0m )\n\u001b[1;32m     66\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mclient_ws\u001b[39;00m \u001b[39mimport\u001b[39;00m ClientWebSocketResponse \u001b[39mas\u001b[39;00m ClientWebSocketResponse\n",
      "File \u001b[0;32m~/software/anaconda3/envs/spark/lib/python3.9/site-packages/aiohttp/client_reqrep.py:72\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:  \u001b[39m# pragma: no cover\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mcharset_normalizer\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mchardet\u001b[39;00m  \u001b[39m# type: ignore[no-redef]\u001b[39;00m\n\u001b[1;32m     75\u001b[0m __all__ \u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39mClientRequest\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mClientResponse\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mRequestInfo\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mFingerprint\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/software/anaconda3/envs/spark/lib/python3.9/site-packages/charset_normalizer/__init__.py:23\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mCharset-Normalizer\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m~~~~~~~~~~~~~~\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39m:license: MIT, see LICENSE for more details.\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcharset_normalizer\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m \u001b[39mimport\u001b[39;00m from_fp, from_path, from_bytes, normalize\n\u001b[1;32m     24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcharset_normalizer\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlegacy\u001b[39;00m \u001b[39mimport\u001b[39;00m detect\n",
      "File \u001b[0;32m~/software/anaconda3/envs/spark/lib/python3.9/site-packages/charset_normalizer/api.py:10\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcharset_normalizer\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconstant\u001b[39;00m \u001b[39mimport\u001b[39;00m TOO_SMALL_SEQUENCE, TOO_BIG_SEQUENCE, IANA_SUPPORTED\n\u001b[0;32m---> 10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcharset_normalizer\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmd\u001b[39;00m \u001b[39mimport\u001b[39;00m mess_ratio\n\u001b[1;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcharset_normalizer\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m CharsetMatches, CharsetMatch\n",
      "File \u001b[0;32m~/software/anaconda3/envs/spark/lib/python3.9/site-packages/charset_normalizer/md.py:5\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcharset_normalizer\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconstant\u001b[39;00m \u001b[39mimport\u001b[39;00m UNICODE_SECONDARY_RANGE_KEYWORD\n\u001b[0;32m----> 5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcharset_normalizer\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m is_punctuation, is_symbol, unicode_range, is_accentuated, is_latin, \\\n\u001b[1;32m      6\u001b[0m     remove_accent, is_separator, is_cjk, is_case_variable, is_hangul, is_katakana, is_hiragana, is_ascii, is_thai\n\u001b[1;32m      9\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mMessDetectorPlugin\u001b[39;00m:\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'COMMON_SAFE_ASCII_CHARACTERS' from 'charset_normalizer.constant' (/home/aromston/software/anaconda3/envs/spark/lib/python3.9/site-packages/charset_normalizer/constant.py)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m     output_file \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39ms3://auctus-ssm/\u001b[39m\u001b[39m{\u001b[39;00mfilename\u001b[39m}\u001b[39;00m\u001b[39m/data.parquet\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     15\u001b[0m     dataframe\u001b[39m.\u001b[39mto_parquet(\u001b[39m\"\u001b[39m\u001b[39ms3://AKIAVBQNNS3MXTP637OG:EWyTmuitu+w3cd2OI5ra8OTMJIqLMAxl7TiJKwKo/test.parquet\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m main()\n",
      "Cell \u001b[0;32mIn[2], line 8\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m data \u001b[39m=\u001b[39m {\u001b[39m0\u001b[39m: {\u001b[39m\"\u001b[39m\u001b[39mdata1\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mvalue1\u001b[39m\u001b[39m\"\u001b[39m}}\n\u001b[1;32m      7\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame\u001b[39m.\u001b[39mfrom_dict(data, orient\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m _write_dataframe_to_parquet_on_s3(df ,\u001b[39m\"\u001b[39;49m\u001b[39mfile.parquet\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[2], line 15\u001b[0m, in \u001b[0;36m_write_dataframe_to_parquet_on_s3\u001b[0;34m(dataframe, filename)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mWriting \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m records to \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mlen\u001b[39m(dataframe), filename))\n\u001b[1;32m     14\u001b[0m output_file \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39ms3://auctus-ssm/\u001b[39m\u001b[39m{\u001b[39;00mfilename\u001b[39m}\u001b[39;00m\u001b[39m/data.parquet\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> 15\u001b[0m dataframe\u001b[39m.\u001b[39;49mto_parquet(\u001b[39m\"\u001b[39;49m\u001b[39ms3://AKIAVBQNNS3MXTP637OG:EWyTmuitu+w3cd2OI5ra8OTMJIqLMAxl7TiJKwKo/test.parquet\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/software/anaconda3/envs/spark/lib/python3.9/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/software/anaconda3/envs/spark/lib/python3.9/site-packages/pandas/core/frame.py:2976\u001b[0m, in \u001b[0;36mDataFrame.to_parquet\u001b[0;34m(self, path, engine, compression, index, partition_cols, storage_options, **kwargs)\u001b[0m\n\u001b[1;32m   2889\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2890\u001b[0m \u001b[39mWrite a DataFrame to the binary parquet format.\u001b[39;00m\n\u001b[1;32m   2891\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2972\u001b[0m \u001b[39m>>> content = f.read()\u001b[39;00m\n\u001b[1;32m   2973\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2974\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mio\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mparquet\u001b[39;00m \u001b[39mimport\u001b[39;00m to_parquet\n\u001b[0;32m-> 2976\u001b[0m \u001b[39mreturn\u001b[39;00m to_parquet(\n\u001b[1;32m   2977\u001b[0m     \u001b[39mself\u001b[39;49m,\n\u001b[1;32m   2978\u001b[0m     path,\n\u001b[1;32m   2979\u001b[0m     engine,\n\u001b[1;32m   2980\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[1;32m   2981\u001b[0m     index\u001b[39m=\u001b[39;49mindex,\n\u001b[1;32m   2982\u001b[0m     partition_cols\u001b[39m=\u001b[39;49mpartition_cols,\n\u001b[1;32m   2983\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[1;32m   2984\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   2985\u001b[0m )\n",
      "File \u001b[0;32m~/software/anaconda3/envs/spark/lib/python3.9/site-packages/pandas/io/parquet.py:430\u001b[0m, in \u001b[0;36mto_parquet\u001b[0;34m(df, path, engine, compression, index, storage_options, partition_cols, **kwargs)\u001b[0m\n\u001b[1;32m    426\u001b[0m impl \u001b[39m=\u001b[39m get_engine(engine)\n\u001b[1;32m    428\u001b[0m path_or_buf: FilePath \u001b[39m|\u001b[39m WriteBuffer[\u001b[39mbytes\u001b[39m] \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mBytesIO() \u001b[39mif\u001b[39;00m path \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m path\n\u001b[0;32m--> 430\u001b[0m impl\u001b[39m.\u001b[39;49mwrite(\n\u001b[1;32m    431\u001b[0m     df,\n\u001b[1;32m    432\u001b[0m     path_or_buf,\n\u001b[1;32m    433\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[1;32m    434\u001b[0m     index\u001b[39m=\u001b[39;49mindex,\n\u001b[1;32m    435\u001b[0m     partition_cols\u001b[39m=\u001b[39;49mpartition_cols,\n\u001b[1;32m    436\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[1;32m    437\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    438\u001b[0m )\n\u001b[1;32m    440\u001b[0m \u001b[39mif\u001b[39;00m path \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(path_or_buf, io\u001b[39m.\u001b[39mBytesIO)\n",
      "File \u001b[0;32m~/software/anaconda3/envs/spark/lib/python3.9/site-packages/pandas/io/parquet.py:176\u001b[0m, in \u001b[0;36mPyArrowImpl.write\u001b[0;34m(self, df, path, compression, index, storage_options, partition_cols, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m     from_pandas_kwargs[\u001b[39m\"\u001b[39m\u001b[39mpreserve_index\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m index\n\u001b[1;32m    174\u001b[0m table \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi\u001b[39m.\u001b[39mTable\u001b[39m.\u001b[39mfrom_pandas(df, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfrom_pandas_kwargs)\n\u001b[0;32m--> 176\u001b[0m path_or_handle, handles, kwargs[\u001b[39m\"\u001b[39m\u001b[39mfilesystem\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m _get_path_or_handle(\n\u001b[1;32m    177\u001b[0m     path,\n\u001b[1;32m    178\u001b[0m     kwargs\u001b[39m.\u001b[39;49mpop(\u001b[39m\"\u001b[39;49m\u001b[39mfilesystem\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    179\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[1;32m    180\u001b[0m     mode\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mwb\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    181\u001b[0m     is_dir\u001b[39m=\u001b[39;49mpartition_cols \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    182\u001b[0m )\n\u001b[1;32m    183\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    184\u001b[0m     \u001b[39misinstance\u001b[39m(path_or_handle, io\u001b[39m.\u001b[39mBufferedWriter)\n\u001b[1;32m    185\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(path_or_handle, \u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    186\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(path_or_handle\u001b[39m.\u001b[39mname, (\u001b[39mstr\u001b[39m, \u001b[39mbytes\u001b[39m))\n\u001b[1;32m    187\u001b[0m ):\n\u001b[1;32m    188\u001b[0m     path_or_handle \u001b[39m=\u001b[39m path_or_handle\u001b[39m.\u001b[39mname\n",
      "File \u001b[0;32m~/software/anaconda3/envs/spark/lib/python3.9/site-packages/pandas/io/parquet.py:84\u001b[0m, in \u001b[0;36m_get_path_or_handle\u001b[0;34m(path, fs, storage_options, mode, is_dir)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[39mif\u001b[39;00m is_fsspec_url(path_or_handle) \u001b[39mand\u001b[39;00m fs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     82\u001b[0m     fsspec \u001b[39m=\u001b[39m import_optional_dependency(\u001b[39m\"\u001b[39m\u001b[39mfsspec\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 84\u001b[0m     fs, path_or_handle \u001b[39m=\u001b[39m fsspec\u001b[39m.\u001b[39;49mcore\u001b[39m.\u001b[39;49murl_to_fs(\n\u001b[1;32m     85\u001b[0m         path_or_handle, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m(storage_options \u001b[39mor\u001b[39;49;00m {})\n\u001b[1;32m     86\u001b[0m     )\n\u001b[1;32m     87\u001b[0m \u001b[39melif\u001b[39;00m storage_options \u001b[39mand\u001b[39;00m (\u001b[39mnot\u001b[39;00m is_url(path_or_handle) \u001b[39mor\u001b[39;00m mode \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m     88\u001b[0m     \u001b[39m# can't write to a remote url\u001b[39;00m\n\u001b[1;32m     89\u001b[0m     \u001b[39m# without making use of fsspec at the moment\u001b[39;00m\n\u001b[1;32m     90\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mstorage_options passed with buffer, or non-supported URL\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/software/anaconda3/envs/spark/lib/python3.9/site-packages/fsspec/core.py:363\u001b[0m, in \u001b[0;36murl_to_fs\u001b[0;34m(url, **kwargs)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39murl_to_fs\u001b[39m(url, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    344\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[39m    Turn fully-qualified and potentially chained URL into filesystem instance\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[39m        The file-systems-specific URL for ``url``.\u001b[39;00m\n\u001b[1;32m    362\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 363\u001b[0m     chain \u001b[39m=\u001b[39m _un_chain(url, kwargs)\n\u001b[1;32m    364\u001b[0m     inkwargs \u001b[39m=\u001b[39m {}\n\u001b[1;32m    365\u001b[0m     \u001b[39m# Reverse iterate the chain, creating a nested target_* structure\u001b[39;00m\n",
      "File \u001b[0;32m~/software/anaconda3/envs/spark/lib/python3.9/site-packages/fsspec/core.py:325\u001b[0m, in \u001b[0;36m_un_chain\u001b[0;34m(path, kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[39mfor\u001b[39;00m bit \u001b[39min\u001b[39;00m \u001b[39mreversed\u001b[39m(bits):\n\u001b[1;32m    324\u001b[0m     protocol \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mprotocol\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39mor\u001b[39;00m split_protocol(bit)[\u001b[39m0\u001b[39m] \u001b[39mor\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mfile\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 325\u001b[0m     \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m get_filesystem_class(protocol)\n\u001b[1;32m    326\u001b[0m     extra_kwargs \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_get_kwargs_from_urls(bit)\n\u001b[1;32m    327\u001b[0m     kws \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(protocol, {})\n",
      "File \u001b[0;32m~/software/anaconda3/envs/spark/lib/python3.9/site-packages/fsspec/registry.py:218\u001b[0m, in \u001b[0;36mget_filesystem_class\u001b[0;34m(protocol)\u001b[0m\n\u001b[1;32m    216\u001b[0m         register_implementation(protocol, _import_class(bit[\u001b[39m\"\u001b[39m\u001b[39mclass\u001b[39m\u001b[39m\"\u001b[39m]))\n\u001b[1;32m    217\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 218\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(bit[\u001b[39m\"\u001b[39m\u001b[39merr\u001b[39m\u001b[39m\"\u001b[39m]) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m registry[protocol]\n\u001b[1;32m    220\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mcls\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mprotocol\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39min\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39mabstract\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n",
      "\u001b[0;31mImportError\u001b[0m: Install s3fs to access S3"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "def main():\n",
    "    data = {0: {\"data1\": \"value1\"}}\n",
    "    df = pd.DataFrame.from_dict(data, orient='index')\n",
    "    _write_dataframe_to_parquet_on_s3(df ,\"file.parquet\")\n",
    "\n",
    "\n",
    "def _write_dataframe_to_parquet_on_s3(dataframe, filename):\n",
    "    \"\"\" Write a dataframe to a Parquet on S3 \"\"\"\n",
    "    print(\"Writing {} records to {}\".format(len(dataframe), filename))\n",
    "    output_file = f\"s3://auctus-ssm/{filename}/data.parquet\"\n",
    "    dataframe.to_parquet(\"s3://AKIAVBQNNS3MXTP637OG:EWyTmuitu+w3cd2OI5ra8OTMJIqLMAxl7TiJKwKo/test.parquet\")\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
